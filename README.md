# ğŸŒŸ Lumos Navigation App for the Visually Impaired 

**Lumos** is an accessibility-focused navigation app designed to help visually impaired users navigate safely and efficiently. It combines **real-time object detection** , **voice-guided navigation** , and **offline support**  in a single Flutter-based application.

This project was created for the **ğŸƒ Hackoween Hackathon**!  

---

## ğŸ‘©â€ğŸ’» Team Members
- **Tanisha Mathur** 
- **Sanchita Sunil**   
- **Archana Shivakumar**  
- **Sudev Suresh** 

For queries or collaboration, reach us via **ğŸ“§ Gmail** or **ğŸ”— LinkedIn**.

---

## ğŸš€ Features

### ğŸŒ Online Model (Requires Internet)
Powered by **Gemini API** for real-time processing.

1. **ğŸ” Surroundings Detection**
   - Real-time object detection using the online model.
   - Voice output describing nearby objects.
   - Voice input supported for interaction.

2. **ğŸ’¡ Flashlight Control**
   - Tap to switch on the flashlight.
   - Tap again to switch it off.

3. **ğŸ—ºï¸ Voice Navigation**
   - Navigate from **Place A to Place B** using **Google Maps** API.
   - Voice-guided directions ensure hands-free navigation.

4. **ğŸ—ºï¸ Plain Maps**
   - Opens Google Maps for manual navigation.

---

### ğŸ“¦ Offline Model (Works Without Internet)
Powered by **COCO dataset** with **SSD MobileNetV1 (TF Lite)** model.

- Detects objects in real-time without internet connectivity.  
- Ensures accessibility even in areas with poor or no network coverage.  

---

### ğŸ”€ Smart Switch
- Automatically checks if the device has network connectivity.  
- Switches between **offline** and **online** models based on network availability.  

---

## ğŸ› ï¸ Built With
- **Flutter** â€“ Cross-platform mobile framework ğŸ–¥ï¸ğŸ“±  
- **Dart** â€“ Programming language used for Flutter development ğŸ“  
- **TensorFlow Lite** â€“ For offline model inference ğŸ¤–  
- **Gemini API** â€“ For online real-time object detection ğŸŒ  
- **Google Maps API** â€“ For navigation and directions ğŸ—ºï¸  

---

## ğŸ® Usage

1. Launch the app ğŸš€  
2. The **smart switch** automatically selects the appropriate model (online/offline) ğŸ”„  
3. Use the buttons to:
   - **ğŸ” Check surroundings** (object detection with voice output)  
   - **ğŸ’¡ Toggle flashlight**  
   - **ğŸ—£ï¸ Enable voice-guided navigation**  
   - **ğŸ—ºï¸ Open plain maps**  
4. Follow voice instructions for safe and accessible navigation âœ…  

---

## âš™ï¸ Installation

1. Ensure **Flutter SDK** is installed âš¡  
2. Clone the repository:
   ```bash
   git clone <repository-url>
